{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VuCBty_omqJW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "1ws5cFH4VcHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize the MNIST dataset using precomputed mean and standard deviation.\n",
        "# These values help improve training stability and convergence speed by ensuring that the pixel values\n",
        "# are centered around 0 and have a standard deviation of 1.\n",
        "\n",
        "# Precomputed values for the MNIST dataset:\n",
        "#   - Mean (μ) = 0.1307\n",
        "#   - Standard Deviation (σ) = 0.3081"
      ],
      "metadata": {
        "id": "VuCBty_omqJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
      ],
      "metadata": {
        "id": "yYigvl1sVep6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):               # B -> Batch Size\n",
        "        x = self.relu(self.conv1(x))    # find simple patterns -> (B, 32, 28, 28)\n",
        "        x = self.relu(self.conv2(x))    # build more complex patterns -> (B, 64, 28, 28)\n",
        "        x = self.pool(x)                # down‑sample, keep strongest signals  -> (B, 64, 14, 14)\n",
        "        x = x.view(x.size(0), -1)       # flatten to a vector -> (B, 12544)\n",
        "        x = self.relu(self.fc1(x))      # mix into 128 features -> (B, 128)\n",
        "        x = self.fc2(x)                 # final 10 class scores -> (B, 10)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tbi4c5C8VlOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model, train_loader, test_loader, device, epochs=5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.5)  # reduce LR by a factor of 0.5 every epochs, allows big steps then finer tuning\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1} - Training Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), \"model.pth\")\n"
      ],
      "metadata": {
        "id": "jqTKIUsIfBKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNNModel().to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "train(model, train_loader, test_loader, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL0JZNfefQOY",
        "outputId": "0770a619-21b0-4241-bd5b-fad3c8f971b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.1962\n",
            "Epoch 1, Batch 200, Loss: 0.0523\n",
            "Epoch 1, Batch 300, Loss: 0.0316\n",
            "Epoch 1, Batch 400, Loss: 0.0727\n",
            "Epoch 1 - Training Loss: 0.1342, Accuracy: 95.84%\n",
            "Epoch 2, Batch 100, Loss: 0.0419\n",
            "Epoch 2, Batch 200, Loss: 0.0960\n",
            "Epoch 2, Batch 300, Loss: 0.0051\n",
            "Epoch 2, Batch 400, Loss: 0.0114\n",
            "Epoch 2 - Training Loss: 0.0302, Accuracy: 99.09%\n",
            "Epoch 3, Batch 100, Loss: 0.0371\n",
            "Epoch 3, Batch 200, Loss: 0.0112\n",
            "Epoch 3, Batch 300, Loss: 0.0018\n",
            "Epoch 3, Batch 400, Loss: 0.0082\n",
            "Epoch 3 - Training Loss: 0.0162, Accuracy: 99.54%\n",
            "Epoch 4, Batch 100, Loss: 0.0020\n",
            "Epoch 4, Batch 200, Loss: 0.0042\n",
            "Epoch 4, Batch 300, Loss: 0.0065\n",
            "Epoch 4, Batch 400, Loss: 0.0004\n",
            "Epoch 4 - Training Loss: 0.0093, Accuracy: 99.77%\n",
            "Epoch 5, Batch 100, Loss: 0.0136\n",
            "Epoch 5, Batch 200, Loss: 0.0066\n",
            "Epoch 5, Batch 300, Loss: 0.0013\n",
            "Epoch 5, Batch 400, Loss: 0.0029\n",
            "Epoch 5 - Training Loss: 0.0066, Accuracy: 99.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Evaluation"
      ],
      "metadata": {
        "id": "uWXziwR40poy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)#fwd\n",
        "\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "i7LMVn0rVmOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluate(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6TAyeAneoB7",
        "outputId": "e7af9117-facd-481e-927e-39cc69fe5c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Demo Testing"
      ],
      "metadata": {
        "id": "YQDrSSZe0k55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets\n",
        "!pip install ipycanvas\n"
      ],
      "metadata": {
        "id": "kEn-GLUGWVJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from ipycanvas import Canvas\n",
        "from PIL import Image\n",
        "from spikingjelly.activation_based import functional\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time"
      ],
      "metadata": {
        "id": "W8PnIxExVqih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_drawing(x, y):\n",
        "    global drawing\n",
        "    drawing = True\n",
        "    canvas.stroke_style = 'white'\n",
        "    canvas.line_width = 20\n",
        "    canvas.begin_path()\n",
        "    canvas.move_to(x, y)\n",
        "\n",
        "def draw(x, y):\n",
        "    if drawing:\n",
        "        canvas.line_to(x, y)\n",
        "        canvas.stroke()\n",
        "\n",
        "def stop_drawing(x, y):\n",
        "    global drawing\n",
        "    drawing = False\n",
        "    predict_drawing()\n"
      ],
      "metadata": {
        "id": "4-4_zp0RvNo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_drawing(image):\n",
        "    img = np.array(image)\n",
        "    # to fit input params, image is 512x512, need to put into 28x28\n",
        "    img = Image.fromarray((img).astype(np.uint8)).resize((28, 28))\n",
        "    img = np.array(img)\n",
        "    img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 28, 28]\n",
        "    return img\n",
        "\n",
        "def load_model(model_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = CNNModel().to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    return model, device\n",
        "\n",
        "def predict_drawing():\n",
        "    model_path = 'model.pth'\n",
        "    model, device = load_model(model_path)\n",
        "\n",
        "    img_data = canvas.get_image_data(0, 0, 512, 512)\n",
        "    img_pil = Image.fromarray(img_data).convert('L')\n",
        "    img_np = np.array(img_pil)\n",
        "\n",
        "    img = process_drawing(img_np)  #  [1, 1, 28, 28] normalized\n",
        "    img = img.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(img)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_digit = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "    print(\"Probabilities:\", probabilities.cpu().numpy())\n",
        "    print(f\"Predicted digit: {predicted_digit}\")\n",
        "\n",
        "    img_display = img.squeeze().cpu().numpy()\n",
        "    plt.imshow(img_display, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_digit}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "fAul7dzkGJv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "canvas = Canvas(width=512, height=512, sync_image_data=True)\n",
        "canvas.fill_style = 'black'\n",
        "canvas.fill_rect(0, 0, canvas.width, canvas.height)\n",
        "\n",
        "# display the canvas in Colab\n",
        "display(canvas)\n",
        "canvas.on_mouse_move(draw)\n",
        "canvas.on_mouse_up(stop_drawing)\n",
        "canvas.on_mouse_down(start_drawing)\n"
      ],
      "metadata": {
        "id": "Cp454CwZW_Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "6iIE_plbWypQ"
      }
    }
  ]
}