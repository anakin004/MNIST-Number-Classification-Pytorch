{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from ipycanvas import Canvas\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuCBty_omqJW"
      },
      "source": [
        "# Normalize the MNIST dataset using precomputed mean and standard deviation.\n",
        "# These values help improve training stability and convergence speed by ensuring that the pixel values\n",
        "# are centered around 0 and have a standard deviation of 1.\n",
        "\n",
        "# Precomputed values for the MNIST dataset:\n",
        "#   - Mean (μ) = 0.1307\n",
        "#   - Standard Deviation (σ) = 0.3081"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYigvl1sVep6"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbi4c5C8VlOQ"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self._init_fc()\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flattened_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    # dynamic flatten size calc\n",
        "    def _init_fc(self):\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 1, 28, 28)\n",
        "            x = self.pool(F.relu(self.bn1(self.conv1(dummy_input))))\n",
        "            x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "            self.flattened_size = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):               # B -> Batch Size\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # (B, 32, 14, 14)\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # (B, 64, 7, 7)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)                      # flatten -> (B, 64*7*7)\n",
        "        x = F.relu(self.fc1(x))                        # hidden dense layer\n",
        "        x = self.dropout(x)                            # apply dropout to generalize\n",
        "        x = self.fc2(x)                                # output logits\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqTKIUsIfBKh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, train_loader, device, epochs=5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.1)  # reduce LR by a factor of 0.5 every epochs, allows big steps then finer tuning\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (batch_idx + 1) % 25 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1} - Training Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), \"model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL0JZNfefQOY",
        "outputId": "0770a619-21b0-4241-bd5b-fad3c8f971b8"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNModel().to(device)\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "train(model, train_loader, device, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWXziwR40poy"
      },
      "source": [
        "#Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7LMVn0rVmOX"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)#fwd\n",
        "\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6TAyeAneoB7",
        "outputId": "e7af9117-facd-481e-927e-39cc69fe5c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 99.08%\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDrSSZe0k55"
      },
      "source": [
        "#Demo Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8PnIxExVqih"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from ipycanvas import Canvas\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-4_zp0RvNo_"
      },
      "outputs": [],
      "source": [
        "def start_drawing(x, y):\n",
        "    global drawing\n",
        "    drawing = True\n",
        "    canvas.stroke_style = 'white'\n",
        "    canvas.line_width = 20\n",
        "    canvas.begin_path()\n",
        "    canvas.move_to(x, y)\n",
        "\n",
        "def draw(x, y):\n",
        "    if drawing:\n",
        "        canvas.line_to(x, y)\n",
        "        canvas.stroke()\n",
        "\n",
        "def stop_drawing(x, y):\n",
        "    global drawing\n",
        "    drawing = False\n",
        "    predict_drawing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAul7dzkGJv7"
      },
      "outputs": [],
      "source": [
        "def process_drawing(image):\n",
        "    img = np.array(image)\n",
        "    # to fit input params, image is 256x256, need to put into 28x28\n",
        "    img = Image.fromarray((img).astype(np.uint8)).resize((28, 28))\n",
        "    img = np.array(img)\n",
        "    img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # [1, 1, 28, 28]\n",
        "    return img\n",
        "\n",
        "def load_model(model_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = CNNModel().to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    return model, device\n",
        "\n",
        "def predict_drawing():\n",
        "    model_path = 'model.pth'\n",
        "    model, device = load_model(model_path)\n",
        "\n",
        "    img_data = canvas.get_image_data(0, 0, 256, 256)\n",
        "    img_pil = Image.fromarray(img_data).convert('L')\n",
        "    img_np = np.array(img_pil)\n",
        "\n",
        "    img = process_drawing(img_np)  #  [1, 1, 28, 28] normalized\n",
        "    img = img.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(img)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_digit = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "    print(\"Probabilities:\", probabilities.cpu().numpy())\n",
        "    print(f\"Predicted digit: {predicted_digit}\")\n",
        "\n",
        "    img_display = img.squeeze().cpu().numpy()\n",
        "    plt.imshow(img_display, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_digit}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp454CwZW_Rd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "canvas = Canvas(width=256, height=256, sync_image_data=True)\n",
        "canvas.fill_style = 'black'\n",
        "canvas.fill_rect(0, 0, canvas.width, canvas.height)\n",
        "\n",
        "# display the canvas in Colab\n",
        "display(canvas)\n",
        "canvas.on_mouse_move(draw)\n",
        "canvas.on_mouse_up(stop_drawing)\n",
        "canvas.on_mouse_down(start_drawing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iIE_plbWypQ"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VuCBty_omqJW"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
